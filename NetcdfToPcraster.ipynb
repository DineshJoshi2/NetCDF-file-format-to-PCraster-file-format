{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9401a84e",
   "metadata": {},
   "source": [
    "## Converting netCDF Data into PCraster Timeseries format.\n",
    "Coded by: Dinesh Joshi \\\n",
    "Email: joshidinesh0227@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730f631c",
   "metadata": {},
   "source": [
    "## Provide Inputs in below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c6d82ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# varibale name for your data \n",
    "myvar_Prec=\"precip\"\n",
    "myvar_Tmax=\"Tmax\"\n",
    "myvar_Tmin=\"Tmin\"\n",
    "#Spatial Extent\n",
    "Xmin=83.4612379 #182010\n",
    "Xmax=84.425406 #275981\n",
    "Ymin=27.5322386 #3089163\n",
    "Ymax=28.5650621 #3204333"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545be134",
   "metadata": {},
   "source": [
    "###  In the next code cell, we will load the netcdf data and convert it into pcraster timeseries format in the desired resolution as mask file. Run the cell below to execute this code. You can check Prec, Tmax, Tmin subfolders inside the main folder for the resultant data. The processing will take time depending on the amount of data and size of study area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d844b997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "# importing necessary libraries\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "from pcraster import *\n",
    "from pcraster.framework import *\n",
    "\n",
    "# Importing NetCDF file\n",
    "import glob\n",
    "Prec_files = glob.glob(r\"./Netcdf Prec/*.nc\")\n",
    "Tmax_files = glob.glob(r\"./Netcdf Tmax/*.nc\")\n",
    "Tmin_files = glob.glob(r\"./Netcdf Tmin/*.nc\")\n",
    "\n",
    "netcdf= Dataset(Prec_files[0]) # opening netcdf file at index 0\n",
    "\n",
    "# Extracting the indices of the coordinates within the Study Area¶\n",
    "latlog_index=[]\n",
    "for latitude in range(len(netcdf.variables[\"lat\"][:])):\n",
    "    for longitude in range(len(netcdf.variables[\"lon\"][:])):\n",
    "        a=float(netcdf.variables[\"lat\"][latitude])\n",
    "        b=float(netcdf.variables[\"lon\"][longitude])\n",
    "        if Xmin <= b <= Xmax and  Ymin <= a <= Ymax:\n",
    "            latlog_index.append((longitude,latitude))\n",
    "Data=[]\n",
    "for i in range(len(latlog_index)):\n",
    "    data=netcdf.variables[myvar_Prec][0,latlog_index[i][1],latlog_index[i][0]]\n",
    "    latitude=netcdf.variables[\"lat\"][latlog_index[i][1]]\n",
    "    longitude=netcdf.variables[\"lon\"][latlog_index[i][0]]\n",
    "    Data.append((data,longitude,latitude))\n",
    "\n",
    "# Creating a station.txt file with coordinates id\n",
    "with open('coordinates.txt', 'w') as C:\n",
    "        for i in range(len(Data)):\n",
    "            C.write(str(Data[i][1]) + ' ' + str(Data[i][2]) + ' ' + str(i+1))\n",
    "            C.write(\"\\n\")\n",
    "\n",
    "# Creating  time series scaler data text files\n",
    "def timeseriesTSS(myvar,files):\n",
    "    with open(myvar+'TimeseriesData.tss', 'w') as f:\n",
    "        f.write(myvar + \" time series scaler data\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(str(len(latlog_index)+1))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"timestep\")\n",
    "        f.write(\"\\n\")\n",
    "        for i in range(len(latlog_index)):\n",
    "                f.write(str(i))\n",
    "                f.write(\"\\n\")\n",
    "        Timesteps=1\n",
    "        for file in range(len(files)):\n",
    "            for time in range(1,len(Dataset(files[file]).variables[\"time\"][:])+1):\n",
    "                Data=[]\n",
    "                for i in range(len(latlog_index)):\n",
    "                    data=Dataset(files[file]).variables[myvar][time-1,latlog_index[i][1],latlog_index[i][0]]\n",
    "                    Data.append(data)\n",
    "                f.write(str(Timesteps)+' ')\n",
    "                for i in range(len(latlog_index)):\n",
    "                    f.write(str(Data[i])+ ' ')\n",
    "                f.write(str(\"\\n\"))\n",
    "                Timesteps=Timesteps+1\n",
    "timeseriesTSS(myvar_Prec,Prec_files)\n",
    "timeseriesTSS(myvar_Tmax,Tmax_files)\n",
    "timeseriesTSS(myvar_Tmin,Tmin_files)\n",
    "\n",
    "# number of mapfiles\n",
    "LastTimestep = sum([len(Dataset(file).variables[\"time\"][:]) for file in Prec_files])\n",
    "\n",
    "# change the current working directory to GDM Training'\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()\n",
    "\n",
    "# Creating a pcraster map file for point coordinates¶\n",
    "# set the paths to the input and output files\n",
    "coordinates_file = './Data Preprocessing/Netcdf Data/coordinates.txt'\n",
    "mask_file = './Inputs/mask.map'\n",
    "output_file = './Data Preprocessing/Netcdf Data/coordinates.map'\n",
    "\n",
    "# build the command string with the file paths\n",
    "command = ['col2map', '-N', coordinates_file, output_file, '--clone', mask_file]\n",
    "\n",
    "# execute the command using subprocess.run\n",
    "subprocess.run(command)\n",
    "\n",
    "# Interpolation using Inverse distance weighting\n",
    "class InterpolateRainfall(DynamicModel):\n",
    "    def __init__(self, cloneMap):\n",
    "        DynamicModel.__init__(self)\n",
    "        setclone(cloneMap)\n",
    "    \n",
    "    def initial(self):\n",
    "        # Map with coordinates\n",
    "        self.coordinates = self.readmap(\"./Data Preprocessing/Netcdf Data/coordinates\")\n",
    "        # Boolean mask for IDW \n",
    "        self.mask = self.readmap(\"./Inputs/mask\")  \n",
    "        #variable for tss file\n",
    "        self.Prec_DataTSS = \"./Data Preprocessing/Netcdf Data/\"+myvar_Prec+'TimeseriesData.tss' \n",
    "        self.Tmax_DataTSS = \"./Data Preprocessing/Netcdf Data/\"+myvar_Tmax+'TimeseriesData.tss'\n",
    "        self.Tmin_DataTSS = \"./Data Preprocessing/Netcdf Data/\"+myvar_Tmin+'TimeseriesData.tss'\n",
    "        self.thiessenPolygons = spreadzone(cover(self.coordinates,0),1,0)\n",
    "       \n",
    "    def dynamic(self):\n",
    "        # Reading precipitation at coordinates and make dynamic map stations\n",
    "        Prec_DataAtStation = timeinputscalar(self.Prec_DataTSS,self.coordinates)\n",
    "        #IDW interpolation\n",
    "        Prec_DataIDW = inversedistance(self.mask,Prec_DataAtStation,4,0,0)\n",
    "        precipThiessen = timeinputscalar(self.Prec_DataTSS,self.thiessenPolygons)\n",
    "        \n",
    "        # Reading precipitation at coordinates and make dynamic map stations\n",
    "        Tmax_DataAtStation = timeinputscalar(self.Tmax_DataTSS,self.coordinates)\n",
    "        #IDW interpolation\n",
    "        Tmax_DataIDW = inversedistance(self.mask,Tmax_DataAtStation,2,0,0)\n",
    "        \n",
    "        # Reading precipitation at coordinates and make dynamic map stations\n",
    "        Tmin_DataAtStation = timeinputscalar(self.Tmin_DataTSS,self.coordinates)\n",
    "        #IDW interpolation\n",
    "        Tmin_DataIDW = inversedistance(self.mask,Tmin_DataAtStation,2,0,0)\n",
    "        \n",
    "        self.report(Prec_DataIDW,\"./Prec/prec\")\n",
    "        self.report(Tmax_DataIDW,\"./Tmax/tmax\")\n",
    "        self.report(Tmin_DataIDW,\"./Tmin/tmin\")\n",
    "        \n",
    "myModel = InterpolateRainfall(\"./Inputs/mask.map\")\n",
    "dynModelFw = DynamicFramework(myModel, lastTimeStep=LastTimestep, firstTimestep=1) #Adjust first and last time step\n",
    "dynModelFw.run()\n",
    "os.chdir(\"./Data Preprocessing/Netcdf Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d965e664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
